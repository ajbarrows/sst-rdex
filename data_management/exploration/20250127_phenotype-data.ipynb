{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "from abcd_tools.utils.ConfigLoader import load_yaml\n",
    "from abcd_tools.utils.io import load_tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = load_yaml(\"../parameters.yaml\")\n",
    "# params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = params['phenotype_keywords']\n",
    "key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fpaths(keywords: list, base_dir: str) -> list:\n",
    "    \"\"\"Get list of file paths using keywords for ABCD behaviora data.\n",
    "\n",
    "    Args:\n",
    "        keywords (list): List of keywords to search for in file names.\n",
    "        base_dir (str): Base directory to search for files.\n",
    "\n",
    "    Returns:\n",
    "        list: List of file paths that contain the keywords.\n",
    "    \"\"\"\n",
    "    fpaths = []\n",
    "    for k in keywords:\n",
    "        fpaths.extend(glob.glob(base_dir + f\"**/*{k}*.csv\", recursive=True))\n",
    "    return fpaths\n",
    "\n",
    "fpaths = get_fpaths(params['phenotype_keywords'], params['phenotype_base_dir'])\n",
    "fpaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assemble_phenotype_vars(phenotype_vars: dict) -> list:\n",
    "    \"\"\"Parse dictionary of variable names from parameters\n",
    "\n",
    "    Args:\n",
    "        phenotype_vars (dict): dictionary of variable names\n",
    "\n",
    "    Returns:\n",
    "        list: list of variable names\n",
    "    \"\"\"\n",
    "    vars = []\n",
    "    for v in phenotype_vars.values():\n",
    "        vars.extend(list(v))\n",
    "    return vars\n",
    "\n",
    "phenotype_vars = assemble_phenotype_vars(params['phenotype_vars'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['timepoints']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_phenotypes(fpaths: list, timepoints: list, vars: list) -> pd.DataFrame:\n",
    "    \"\"\"Assemble phenotypes from multiple files into a single DataFrame\n",
    "\n",
    "    Args:\n",
    "        fpaths (list): List of file paths\n",
    "        timepoints (list): Timepoints to subset\n",
    "        vars (list): Variables to keep.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Concatenated DataFrame\n",
    "    \"\"\"\n",
    "    phenotypes = pd.DataFrame()\n",
    "    for fpath in fpaths:\n",
    "        tmp = load_tabular(fpath, timepoints=timepoints, cols=vars)\n",
    "        phenotypes = pd.concat([phenotypes, tmp], axis=1)\n",
    "    return phenotypes\n",
    "    \n",
    "phenotypes = load_phenotypes(fpaths, params['timepoints'], phenotype_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_covariates(params: dict) -> pd.DataFrame:\n",
    "    \"\"\"Load covariates from file\n",
    "\n",
    "    Args:\n",
    "        params (dict): Parameters dictionary\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Covariates DataFrame\n",
    "    \"\"\"\n",
    "    demo = load_tabular(params['demo_fpath'], cols=params['demo_vars'], timepoints=params['timepoints'])\n",
    "    general = load_tabular(params['general_fpath'], cols=params['general_vars'], timepoints=params['timepoints'])\n",
    "    covars = pd.concat([demo, general], axis=1)\n",
    "\n",
    "    covars.replace({777: np.nan, 999.0: np.nan}, inplace=True)\n",
    "    return covars\n",
    "\n",
    "def join_covariates(phenotypes: pd.DataFrame, covariates: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Join phenotypes with covariates\n",
    "\n",
    "    Args:\n",
    "        phenotypes (pd.DataFrame): Phenotypes DataFrame\n",
    "        covariates (pd.DataFrame): Covariates DataFrame\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Joined DataFrame\n",
    "    \"\"\"\n",
    "    return phenotypes.join(covariates)\n",
    "\n",
    "\n",
    "covariates = load_covariates(params)\n",
    "phenotypes = join_covariates(covariates, phenotypes)\n",
    "phenotypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_path = \"../../data/01_raw/tabular/core/abcd-general/abcd_p_demo.csv\"\n",
    "demo = load_tabular(demo_path, timepoints=params['timepoints'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo['demo_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_path = \"../../data/01_raw/tabular/core/abcd-general/abcd_y_lt.csv\"\n",
    "general = load_tabular(general_path, timepoints=params['timepoints'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sst-rdex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
