{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import BPt as bp\n",
    "\n",
    "from abcd_tools.utils.io import load_tabular\n",
    "from abcd_tools.utils.ConfigLoader import load_yaml\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import ElasticNet\n",
    "# import missingno as msno\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = load_yaml(\"../parameters.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotype = load_tabular(params[\"phenotype_path\"])\n",
    "phenotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = load_tabular(params[\"behavioral_path\"])\n",
    "predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = predictors.join(phenotype, how='inner')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# msno.matrix(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The BPM has too much missingness to be useful, here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotype = phenotype.loc[:,~phenotype.columns.str.startswith('bpm')]\n",
    "df = predictors.join(phenotype, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_phenotype_scopes(predictors: pd.DataFrame, fpath: str, params: dict) -> dict:\n",
    "\n",
    "    empirical_predictors = ['correct_go_mrt', 'correct_go_stdrt', 'issrt']\n",
    "    covariates = params['covariates']\n",
    "    category = params['categorical']\n",
    "    predictors = predictors.loc[:, ~predictors.columns.isin(covariates)]\n",
    "\n",
    "    rdex_predictors = (predictors.loc[:, ~predictors.columns.isin(empirical_predictors)]\n",
    "                        .columns\n",
    "                        .tolist())\n",
    "\n",
    "    scopes = {\n",
    "        'category'  : category,\n",
    "        'covariates': covariates,\n",
    "        'empirical': empirical_predictors,\n",
    "        'rdex': rdex_predictors,\n",
    "        'rdex + empirical': predictors.columns.tolist()\n",
    "    }\n",
    "\n",
    "    if fpath:\n",
    "        pd.to_pickle(scopes, fpath + 'phenotype_prediction_scopes.pkl')\n",
    "\n",
    "    return scopes\n",
    "\n",
    "# scopes = get_phenotype_scopes(predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rdex_prediction_ds = pd.read_pickle(params[\"rdex_prediction_dataset_path\"])\n",
    "# rdex_prediction_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_phenotype_dataset(rdex_ds: bp.Dataset, predictors: pd.DataFrame, \n",
    "    phenotype: pd.DataFrame, params: dict, fpath: str) -> bp.Dataset:\n",
    "\n",
    "    # gather index from rdex prediction dataset\n",
    "    rdex_ds_train = rdex_ds.train_subjects\n",
    "    rdex_ds_test = rdex_ds.test_subjects\n",
    "    all_subjects = rdex_ds_train.append(rdex_ds_test)\n",
    "\n",
    "    # exclude bpm columns from phenotype -- too much missingness\n",
    "    phenotype = phenotype.loc[:,~phenotype.columns.str.startswith('bpm')]\n",
    "    df = predictors.join(phenotype, how='inner')\n",
    "\n",
    "    # limit to subjects in rdex dataset\n",
    "    df = df.loc[df.index.isin(all_subjects)]\n",
    "\n",
    "    scopes = get_phenotype_scopes(predictors, fpath, params)\n",
    "    targets = phenotype.loc[:, ~phenotype.columns.isin(params['covariates'])].columns\n",
    "\n",
    "    ds = bp.Dataset(df, targets=targets)\n",
    "    ds = ds.set_train_split(subjects=rdex_ds_train)\n",
    "\n",
    "    for k, v in scopes.items():\n",
    "        ds.add_scope(v, k, inplace=True)\n",
    "\n",
    "    ds = ds.ordinalize(scope='category')\n",
    "    ds = ds.dropna()\n",
    "\n",
    "    if fpath:\n",
    "        ds.to_pickle(fpath + 'phenotype_prediction_dataset.pkl')\n",
    "\n",
    "    return ds\n",
    "\n",
    "# ds = prepare_phenotype_dataset(rdex_prediction_ds, predictors, phenotype, params, fpath=params['phenotype_input_dir'])\n",
    "# ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_phenotype_prediction_pipeline() -> bp.Pipeline:\n",
    "   \n",
    "    # Just scale float type features\n",
    "    scaler = bp.Scaler('robust', scope='float')\n",
    "    normalizer = bp.Scaler('normalize', scope='float')\n",
    "\n",
    "\n",
    "    # Define regression model\n",
    "    mod_obj=ElasticNet()\n",
    "    mod_params = {\n",
    "        'alpha': bp.p.Log(lower=1e-5, upper=1e5),\n",
    "        'l1_ratio': bp.p.Scalar(lower=0.001, upper=1).set_mutation(sigma=0.165)}\n",
    "    param_search = bp.ParamSearch('HammersleySearch', n_iter=100, cv='default')\n",
    "\n",
    "    model = bp.Model(\n",
    "        obj=mod_obj, \n",
    "        params=mod_params,  \n",
    "        param_search=param_search\n",
    "    )\n",
    "\n",
    "    # Then define full pipeline\n",
    "    pipe = bp.Pipeline([scaler, normalizer, model])\n",
    "\n",
    "    return pipe\n",
    "\n",
    "def fit_phenotype_prediction_model(ds: bp.Dataset, scopes: dict, n_cores=1, random_state=42) -> bp.CompareDict:\n",
    "\n",
    "    pipe = define_phenotype_prediction_pipeline()\n",
    "    cv = bp.CV(splits=5, n_repeats=1)\n",
    "    ps = bp.ProblemSpec(n_jobs=n_cores, random_state=random_state)\n",
    "\n",
    "    compare_scopes = []\n",
    "    for key in scopes.keys():\n",
    "        compare_scopes.append(bp.Option(['covariates', key], name=key))\n",
    "\n",
    "    results = bp.evaluate(pipeline=pipe,\n",
    "                      dataset=ds,\n",
    "                      problem_spec=ps,\n",
    "                      scope=bp.Compare(compare_scopes),\n",
    "                      target=bp.Compare(ds.get_cols('target')),\n",
    "                      mute_warnings=True,\n",
    "                      cv=cv)\n",
    "\n",
    "    return results\n",
    "\n",
    "def save_model_results(res: bp.CompareDict, name: str, model: str, path: str) -> None:\n",
    "    \"\"\"Save model results to disk.\n",
    "\n",
    "    Args:\n",
    "        res (bp.CompareDict): Model results.\n",
    "        name (str): Model name.\n",
    "        model (str): Model type.\n",
    "        path (str): Path to save results.\n",
    "    \"\"\"\n",
    "    pd.to_pickle(res, f'{path}/{name}_{model}_results.pkl')\n",
    "\n",
    "    summary = res.summary()\n",
    "    summary.to_csv(f'{path}/{name}_{model}_summary.csv')\n",
    "\n",
    "    print(f\"Results saved to {path}\")\n",
    "\n",
    "\n",
    "# n_cores = os.cpu_count() - 2\n",
    "# res = fit_phenotype_prediction_model(ds, scopes, n_cores=n_cores, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_model_results(res, 'phenotype_prediction', 'elastic_net', params['phenotype_output_dir'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run on HPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_summary(res: bp.CompareDict) -> pd.DataFrame:\n",
    "    \"\"\"Helper to get full summary information from BPt models.\n",
    "\n",
    "    Args:\n",
    "        res (bp.CompareDict): Model results.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Full summary information\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    keys = list(res.keys())\n",
    "    repr_key = keys[0]\n",
    "    option_keys = [o.key for o in repr_key.options]\n",
    "    cols = {key: [] for key in option_keys}\n",
    "\n",
    "    score_cols = []\n",
    "\n",
    "    for key in keys:\n",
    "        for option in key.options:\n",
    "            cols[option.key].append(option.name)\n",
    "        \n",
    "        evaluator = res[key]\n",
    "        \n",
    "        attr = getattr(evaluator, 'scores')\n",
    "        new_col_names = []\n",
    "        for key in attr:\n",
    "        \n",
    "            val = attr[key]\n",
    "\n",
    "            new_col_name = 'scores' + '_' + key\n",
    "            new_col_names.append(new_col_name)\n",
    "        \n",
    "            try:\n",
    "                cols[new_col_name].append(val)\n",
    "            except KeyError:\n",
    "                cols[new_col_name] = [val]\n",
    "\n",
    "    s = pd.DataFrame.from_dict(cols)\n",
    "    return s.explode(new_col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.read_pickle(params['phenotype_output_dir'] + '/phenotype_elastic_results.pkl')\n",
    "# summary = pd.read_csv(params['phenotype_output_dir'] + '/phenotype_elastic_summary.csv')\n",
    "\n",
    "\n",
    "def make_phenotype_plot_df(res: bp.CompareDict, params: dict) -> pd.DataFrame:\n",
    "    \"\"\"Make phenotype plot dataframe.\n",
    "\n",
    "    Args:\n",
    "        res (bp.CompareDict): Model results.\n",
    "        params (dict): Parameters.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Phenotype plot dataframe.\n",
    "    \"\"\"\n",
    "\n",
    "    summary = get_full_summary(res)\n",
    "\n",
    "    item_map = params['phenotype_plot_name_keyed']\n",
    "    grouping_map = params['grouping_map']\n",
    "\n",
    "    summary = summary.replace(item_map)\n",
    "    summary = summary.replace(grouping_map)\n",
    "\n",
    "    tmp = summary['target'].str.split(':', expand=True)\n",
    "    tmp.columns = ['grouping', 'item']\n",
    "    summary = pd.concat([summary, tmp], axis=1)\n",
    "\n",
    "    summary = summary.sort_values(['grouping', 'scope', 'scores_r2'], ascending=False)\n",
    "\n",
    "    return summary\n",
    "\n",
    "plot_df = make_phenotype_plot_df(res, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_phenotype_effectsize_plot(plot_df: pd.DataFrame, params: dict) -> None:\n",
    "    \"\"\"Make phenotype effectsize plot.\n",
    "\n",
    "    Args:\n",
    "        plot_df (pd.DataFrame): Plot dataframe.\n",
    "        params (dict): Parameters.\n",
    "    \"\"\"\n",
    "    \n",
    "    sns.set(style='whitegrid', font_scale=2)\n",
    "\n",
    "    g = sns.FacetGrid(plot_df, col='grouping', height=10, sharex=False)\n",
    "    g.map(sns.barplot, 'item', 'scores_r2', 'scope', palette='viridis')\n",
    "    g.set_xticklabels(rotation=45, ha='right')\n",
    "    g.set_titles('{col_name}')\n",
    "    g.set_axis_labels('', '$R^2$')\n",
    "    g.add_legend(title='')\n",
    "\n",
    "    plt.savefig(params['phenotype_plot_output_dir'] + '/phenotype_effectsize_plot.png', bbox_inches='tight', dpi=300)\n",
    "    # plt.show()\n",
    "\n",
    "make_phenotype_effectsize_plot(plot_df, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_phenotype_fis(res: bp.CompareDict, params: dict) -> pd.DataFrame:\n",
    "    \"\"\"Gather phenotype feature importance scores.\n",
    "\n",
    "    Args:\n",
    "        res (bp.CompareDict): Model results.\n",
    "        params (dict): Parameters.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Phenotype feature importance scores.\n",
    "    \"\"\"\n",
    "    \n",
    "    item_map = params['phenotype_plot_name_keyed']\n",
    "    grouping_map = params['grouping_map']\n",
    "\n",
    "    keys = list(res.keys())\n",
    "    fis = pd.DataFrame()\n",
    "    for key in keys:\n",
    "        tmp = res[key].get_fis()\n",
    "        scope = str(key.options[0]).replace('scope=', '')\n",
    "        target = str(key.options[1]).replace('target=', '')\n",
    "\n",
    "        tmp.insert(0, 'scope', scope)\n",
    "        tmp.insert(1, 'target', target)\n",
    "\n",
    "        fis = pd.concat([fis, tmp])\n",
    "        \n",
    "    fis = fis.replace(item_map)\n",
    "    fis = fis.replace(grouping_map)\n",
    "    \n",
    "    tmp = fis['target'].str.split(':', expand=True)\n",
    "    tmp.columns = ['grouping', 'item']\n",
    "    fis = pd.concat([fis, tmp], axis=1)\n",
    "    \n",
    "    return fis\n",
    "fis = gather_phenotype_fis(res, params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_average_fis(fis: pd.DataFrame, params: dict) -> pd.DataFrame:\n",
    "    \"\"\"Make average feature importance scores.\n",
    "\n",
    "    Args:\n",
    "        fis (pd.DataFrame): Feature importance scores.\n",
    "        params (dict): Parameters.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Average feature importance scores.\n",
    "    \"\"\"\n",
    "\n",
    "    covars = params['covariates']\n",
    "    target_map = params['target_map']\n",
    "  \n",
    "    fis = fis.drop(columns=covars)\n",
    "\n",
    "    fisummary = fis.groupby(['grouping', 'scope']).mean().reset_index()\n",
    "    fisummary = fisummary.melt(id_vars=['grouping','scope'], \n",
    "                                var_name='feature', \n",
    "                                value_name='importance')\n",
    "                                \n",
    "    fisummary = fisummary.replace(target_map)\n",
    "    return fisummary\n",
    "\n",
    "avg_fis = make_average_fis(fis, params)\n",
    "avg_fis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_fis['grouping'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_fis['scope'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_fis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_feat_imp_radar_plot(df, ax, legend=True):\n",
    "    \"\"\"Make feature importance radar plot.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Dataframe.\n",
    "        ax (plt.Axes): Axes.\n",
    "        legend (bool, optional): Legend. Defaults to True.\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.dropna()\n",
    "    variables = pd.unique(df['feature'])\n",
    "    N = len(variables)\n",
    "\n",
    "    categories = df['grouping'].unique()\n",
    "    colors = ['#1f77b4','#aec7e8','#ff7f0e']\n",
    "\n",
    "    radians = 2 * np.pi\n",
    "    angles = [n / float(N) * radians for n in range(N)]\n",
    "    angles += angles[:1]\n",
    "\n",
    "    # instantiate plot\n",
    "    ax.set_xticks(angles[:-1], variables)\n",
    "    ax.set_rlabel_position(10)\n",
    "\n",
    "    # plot circle to show 0\n",
    "    rads = np.arange(0, (2 * np.pi), 0.01)\n",
    "    zeros = np.zeros(len(rads))\n",
    "    ax.plot(rads, zeros, 'k', alpha=.5)\n",
    "\n",
    "    # set grid\n",
    "    ax.grid(True)\n",
    "    ax.spines['polar'].set_visible(False)\n",
    "\n",
    "    for category, color in zip(categories, colors):\n",
    "\n",
    "        tmp = df[df['grouping'] == category]\n",
    "\n",
    "        values = tmp['importance'].reset_index(drop=True).values\n",
    "\n",
    "        values = np.append(values, values[0])\n",
    "\n",
    "        ax.plot(angles, values, color=color)\n",
    "\n",
    "    if legend:\n",
    "        legend_labels = np.insert(categories, 0, 'Reference = 0')\n",
    "        ax.legend(legend_labels, bbox_to_anchor=(0, 1.05))\n",
    "\n",
    "\n",
    "def phenotype_feat_important_collage(avg_fis: pd.DataFrame, params: dict) -> None:\n",
    "    \"\"\"Make phenotype feature importance collage.\n",
    "\n",
    "    Args:\n",
    "        avg_fis (pd.DataFrame): Average feature importance scores.\n",
    "        params (dict): Parameters.\n",
    "    \"\"\"\n",
    "\n",
    "    sns.set_theme()\n",
    "    sns.set(style='whitegrid', font_scale=1)\n",
    "\n",
    "    scopes = params['radard_plot_scopes']\n",
    "\n",
    "    fig, ax = plt.subplots(ncols=len(scopes), figsize=(25,25), subplot_kw={'projection': 'polar'})\n",
    "\n",
    "    for i, scope in enumerate(scopes):\n",
    "        legend = True if i == len(scopes)-1 else False\n",
    "        make_feat_imp_radar_plot(avg_fis[avg_fis['scope'] == scope], ax[i], legend=legend)\n",
    "        ax[i].set_title(scope)\n",
    "\n",
    "    plt.savefig(params['phenotype_plot_output_dir'] + '/phenotype_feat_imp_radar_plot.png', bbox_inches='tight', dpi=300)\n",
    "\n",
    "phenotype_feat_important_collage(avg_fis, params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sst-rdex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
