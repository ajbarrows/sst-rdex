{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follows from `rdex-prediction` models: is variance in empirically-derived SSRT explained by RDEX model parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import BPt as bp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "from abcd_tools.utils.ConfigLoader import load_yaml\n",
    "from abcd_tools.utils.io import load_tabular\n",
    "\n",
    "from scipy.stats import pearsonr, spearmanr, gaussian_kde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = load_yaml(\"../parameters.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behavioral = load_tabular(params[\"targets_path\"])\n",
    "behavioral = behavioral.drop(columns=[\"correct_go_mrt\", \"correct_go_stdrt\"]) # drop standard metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also drop model-derrived SSRT, as well as the match and mismatch accumulators as they're compositely defined in EEA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behavioral = behavioral.drop(columns=[\"SSRT\", \"vT\", \"vF\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit dataset to training subjects from rdex_prediction model\n",
    "rdex_predict_ds = pd.read_pickle(params[\"sst_dataset_path\"])\n",
    "predict_train_idx = rdex_predict_ds.train_subjects\n",
    "\n",
    "behavioral = behavioral[behavioral.index.isin(predict_train_idx)]\n",
    "behavioral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_columns = behavioral[['issrt']].columns\n",
    "ds = bp.Dataset(behavioral, targets=target_columns)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_crosspredict_pipeline(ds: bp.Dataset) -> bp.Pipeline:\n",
    "   \n",
    "    # Just scale float type features\n",
    "    scaler = bp.Scaler('robust', scope='float')\n",
    "    normalizer = bp.Scaler('normalize', scope='float')\n",
    "\n",
    "    # Define regression model\n",
    "    # mod_obj=ElasticNet()\n",
    "    mod_obj=\"ridge\"\n",
    "    # mod_params = {\n",
    "    #     'alpha': bp.p.Log(lower=1e-5, upper=1e5),\n",
    "    #     'l1_ratio': bp.p.Scalar(lower=0.001, upper=1).set_mutation(sigma=0.165)}\n",
    "    mod_params = {'alpha': bp.p.Log(lower=1e-5, upper=1e5)}\n",
    "    param_search = bp.ParamSearch('HammersleySearch', n_iter=100, cv='default')\n",
    "    model = bp.Model(\n",
    "        obj=mod_obj, \n",
    "        params=mod_params,  \n",
    "        param_search=param_search\n",
    "    )\n",
    "\n",
    "    # Then define full pipeline\n",
    "    pipe = bp.Pipeline([scaler, normalizer, model])\n",
    "\n",
    "    return pipe\n",
    "\n",
    "def fit_crosspredict_model(ds: bp.Dataset) -> bp.CompareDict:\n",
    "\n",
    "    pipe = define_crosspredict_pipeline(ds)\n",
    "    cv = bp.CV(splits=5, n_repeats=1)\n",
    "    ps = bp.ProblemSpec(n_jobs=8, random_state=42)\n",
    "\n",
    "\n",
    "    results = bp.evaluate(pipeline=pipe,\n",
    "                      dataset=ds,\n",
    "                      problem_spec=ps,\n",
    "                      mute_warnings=True,\n",
    "                      progress_bar=False,\n",
    "                      verbose=0,\n",
    "                      cv=cv)\n",
    "\n",
    "    return results\n",
    "\n",
    "# results = fit_crosspredict_model(ds)\n",
    "# pd.to_pickle(results, params[\"model_results_path\"] + \"crosspredict_model_results.pkl\")\n",
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_pickle(params[\"model_results_path\"] + \"crosspredict_model_results.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plot_df(results: bp.EvalResults, params: dict) -> pd.DataFrame:\n",
    "    fis = results.get_fis()\n",
    "    fis_long = fis.melt()\n",
    "    fis_long['process'] = fis_long['variable'].replace(params['process_map'])\n",
    "    fis_long['variable'] = fis_long['variable'].replace(params['target_map'])\n",
    "\n",
    "    fis_sorted = fis_long.groupby('variable').mean().sort_values('value').index\n",
    "    fis_long = fis_long.set_index('variable').loc[fis_sorted].reset_index()\n",
    "    return fis_long\n",
    "\n",
    "fis_long = make_plot_df(results, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_crosspredict_plot(fis_long: pd.DataFrame, params: dict, metrics: tuple) -> None:\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    palette = params['color_map']\n",
    "\n",
    "    title = f'Feature Importance Predicting Empirical SSRT\\nAvg. $R^2$: {metrics[0]:.2%} $\\pm$ {metrics[1]:.2%}'\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    sns.barplot(x='value', y='variable', hue='process', \n",
    "            data=fis_long, palette=palette, dodge=False, ax=ax)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('Avg. Feature Importance')\n",
    "    ax.set_ylabel('')\n",
    "    ax.legend(title='')\n",
    "\n",
    "    plt.savefig(params['plot_output_path'] + 'crosspredict_feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "metrics = (results.mean_scores['r2'], results.std_scores['r2'])\n",
    "\n",
    "make_crosspredict_plot(fis_long, params, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fis_avg = fis_long.groupby('variable').agg(['mean', 'std'])\n",
    "fis_avg.to_csv(params['model_results_path'] + 'crosspredict_feature_importance.csv')\n",
    "fis_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine N-back EEA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load results\n",
    "nback_sst_res = pd.read_pickle(params['model_results_path'] + 'all_vertex_sst_nback_ridge_results.pkl')\n",
    "sst_res = pd.read_pickle(params['model_results_path'] + 'all_vertex_ridge_results.pkl')\n",
    "nback_res = pd.read_pickle(params['model_results_path'] + 'all_vertex_nback_ridge_results.pkl')\n",
    "\n",
    "nback_eea = pd.read_csv(params['nback_targets_path']).set_index(['src_subject_id', 'eventname'])['e']\n",
    "\n",
    "def assemble_model_data(res, eea_var):\n",
    "    ds = res._dataset\n",
    "    pred_dfs = res.get_preds_dfs()\n",
    "\n",
    "    return ds, pred_dfs\n",
    "\n",
    "# SST EEA predicted using SST task-fMRI\n",
    "sst_ds, sst_preds = assemble_model_data(sst_res['EEA'], 'EEA')\n",
    "\n",
    "# N-Back EEA predicted using SST task-fMRI\n",
    "nback_sst_ds, nback_sst_preds = assemble_model_data(nback_sst_res['e'], 'e')\n",
    "\n",
    "# N-Back EEA predicted using N-Back task-fMRI\n",
    "nback_ds, nback_preds = assemble_model_data(nback_res['e'], 'e')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join with n-back EEA\n",
    "sst_preds = [df.join(nback_eea) for df in sst_preds]\n",
    "sst_preds = pd.concat(sst_preds)\n",
    "sst_preds = sst_preds[~sst_preds.index.duplicated(keep='first')].dropna()\n",
    "\n",
    "nback_sst_preds = pd.concat(nback_sst_preds)\n",
    "nback_sst_preds = nback_sst_preds[~nback_sst_preds.index.duplicated(keep='first')].dropna()\n",
    "\n",
    "nback_preds = pd.concat(nback_preds)\n",
    "nback_preds = nback_preds[~nback_preds.index.duplicated(keep='first')].dropna()\n",
    "\n",
    "# EEA targets\n",
    "eea = pd.concat([sst_ds['EEA'], nback_eea], axis=1).dropna()\n",
    "eea.columns = ['sst_eea', 'nback_eea']\n",
    "\n",
    "target_map = {\n",
    "    'e': 'N-Back EEA',\n",
    "    'nback_mrt': 'RT',\n",
    "    'nback_stdrt': 'RT Variability',\n",
    "}\n",
    "\n",
    "process_map = {\n",
    "    'e': 'EEA',\n",
    "    'nback_mrt': 'empirical',\n",
    "    'nback_stdrt': 'empirical',\n",
    "}\n",
    "    \n",
    "nback_sst_summary = pd.read_csv(params['model_results_path'] + 'vertex_sst_nback_ridge_models_summary.csv')\n",
    "nback_sst_summary['process'] = nback_sst_summary['target'].replace(process_map)\n",
    "nback_sst_summary['target'] = nback_sst_summary['target'].replace(target_map)\n",
    "\n",
    "nback_sst_summary = nback_sst_summary[~nback_sst_summary['target'].str.contains('dprime')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_residual_plot(xvar, yvar, df, xlab, ylab, ax):\n",
    "        values = np.vstack([df[xvar], df[yvar]])\n",
    "        residual_kernel = gaussian_kde(values)(values)\n",
    "\n",
    "        rho, p = spearmanr(df[xvar], df[yvar])\n",
    "\n",
    "        if p < 0.001:\n",
    "            p_str = rf\"$\\rho = {rho:.2f}, p < 0.001$\"\n",
    "        else:\n",
    "            p_str = rf\"$\\rho = {rho:.2f}, p = {p:.2f}\"\n",
    "\n",
    "\n",
    "        # sns.scatterplot(x=xvar, y=yvar, data=df,\n",
    "        #         alpha=0.5, s=8, ax=ax, c=residual_kernel, lowess=True)\n",
    "\n",
    "        sns.regplot(x=xvar, y=yvar, data=df, ax=ax, lowess=True,\n",
    "                scatter_kws={'alpha': 0.0})\n",
    "        scatter = ax.scatter(df[xvar], df[yvar],\n",
    "                alpha=0.25, s=5, c=residual_kernel, cmap='viridis')\n",
    "\n",
    "        # need line to keep things equal, apparently\n",
    "        line_min = min(df[xvar].min(), df[yvar].min())\n",
    "        line_max = max(df[xvar].max(), df[yvar].max())\n",
    "\n",
    "        ax.plot([line_min, line_max], [line_min, line_max], color='black', alpha=0.0)\n",
    "\n",
    "        ax.set_xlabel(xlab)\n",
    "        ax.set_ylabel(ylab)\n",
    "        ax.text(0.05, 0.95, \"Residuals\", ha='left', va='top', transform=ax.transAxes)\n",
    "        ax.text(0.05, 0.88, p_str, ha='left', va='top', transform=ax.transAxes)\n",
    "\n",
    "        # ax.set_aspect('equal', 'box')\n",
    "\n",
    "        return residual_kernel\n",
    "\n",
    "def make_correlation_plot(xvar, yvar, df, xlab, ylab, ax):\n",
    "        values = np.vstack([df[xvar], df[yvar]])\n",
    "        parameter_kernel = gaussian_kde(values)(values)\n",
    "\n",
    "        rho, p = spearmanr(df[xvar], df[yvar])\n",
    "        if p < 0.001:\n",
    "            p_str = rf\"$\\rho = {rho:.2f}, p < 0.001$\"\n",
    "        else:\n",
    "            p_str = rf\"$\\rho = {rho:.2f}, p = {p:.2f}\"\n",
    "\n",
    "        sns.regplot(x=xvar, y=yvar, data=df, ax=ax, lowess=True,\n",
    "                scatter_kws={'alpha': 0.0})\n",
    "\n",
    "        scatter = ax.scatter(df[xvar], df[yvar],\n",
    "                alpha=0.25, s=5, c=parameter_kernel, cmap='magma')\n",
    "\n",
    "        ax.set_xlabel(xlab)\n",
    "        ax.set_ylabel(ylab)\n",
    "        ax.text(0.05, 0.95, p_str, ha='left', va\n",
    "        ='top', transform=ax.transAxes)\n",
    "\n",
    "        return parameter_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_plot(ax, label):\n",
    "    ax.set_title(label,\n",
    "        fontdict={'fontsize': 14, 'fontweight': 'bold'},\n",
    "        loc='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(\"paper\", font_scale=1.25)\n",
    "grid = {'width_ratios': [1, .25, 1, 1, 1]}\n",
    "fig, axs = plt.subplots(nrows=1, ncols=5, figsize=(14, 4), \n",
    "                        layout='constrained', gridspec_kw=grid)\n",
    "\n",
    "\n",
    "parameter_kernel = make_correlation_plot('nback_eea', 'sst_eea', eea, 'N-Back EEA Estimates', 'SST EEA Estimates', axs[0])\n",
    "axs[0].xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "vmin = parameter_kernel.min()\n",
    "vmax = parameter_kernel.max()\n",
    "points = plt.scatter([], [], c=[], vmin=vmin, vmax=vmax, cmap='magma')\n",
    "cbar = fig.colorbar(points, ax=axs[0], orientation='vertical', fraction=0.025, ticks=[])\n",
    "cbar.set_label('Point Density')\n",
    "label_plot(axs[0], \"a)\")\n",
    "\n",
    "axs[1].axis('off')\n",
    "\n",
    "sst_kernel = make_residual_plot('y_true', 'predict', sst_preds, 'SST EEA Estimates', 'SST EEA Predicted from SST task-fMRI', axs[2])\n",
    "label_plot(axs[2], \"b)\")\n",
    "\n",
    "nback_kernel = make_residual_plot('y_true', 'predict', nback_preds, 'N-Back EEA Estimates', 'N-Back EEA Predicted from N-Back task-fMRI', axs[3])\n",
    "axs[3].xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "axs[3].yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "label_plot(axs[3], \"c)\")\n",
    "\n",
    "nback_sst_kernel = make_residual_plot('y_true', 'predict', nback_sst_preds, 'N-Back EEA Estimates', 'N-Back EEA Predicted from SST task-fMRI', axs[4])\n",
    "axs[4].xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "axs[4].yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "label_plot(axs[4], \"d)\")\n",
    "\n",
    "vmin = min(sst_kernel.min(), nback_kernel.min(), nback_sst_kernel.min())\n",
    "vmax = max(sst_kernel.max(), nback_kernel.max(), nback_sst_kernel.max())\n",
    "\n",
    "points = plt.scatter([], [], c=[], vmin=vmin, vmax=vmax, cmap='viridis')\n",
    "cbar = fig.colorbar(points, ax=axs[4], orientation='vertical', fraction=0.025, ticks=[])\n",
    "cbar.set_label('Point Density')\n",
    "\n",
    "\n",
    "# axs[3].sharey(axs[4])\n",
    "\n",
    "axs[0].set_aspect(1./axs[0].get_data_ratio())\n",
    "axs[0].xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "for i in [2, 3, 4]:\n",
    "    axs[i].set_aspect('equal', 'box')\n",
    "    axs[i].xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    axs[i].yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "axs[0].sharey(axs[2])\n",
    "sns.despine()\n",
    "\n",
    "\n",
    "plt.savefig(params['plot_output_path'] + 'nback_sst_eea_correlations.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sst-rdex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
