{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Mask feature importance for salience network using Yeo et al 2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from nilearn import datasets\n",
    "from nilearn.surface import load_surf_data\n",
    "\n",
    "import neurotools.plotting as ntp\n",
    "\n",
    "from abcd_tools.utils.ConfigLoader import load_yaml\n",
    "params = load_yaml('../parameters.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Load Freesurfer fsaverage5 Yeo2011 network atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_templates = \"../../data/01_raw/label/\"\n",
    "yeo_lh_path = fs_templates + \"lh.Yeo2011_7Networks_N1000.annot\"\n",
    "yeo_rh_path = fs_templates + \"rh.Yeo2011_7Networks_N1000.annot\"\n",
    "\n",
    "yeo_lh_atlas = load_surf_data(yeo_lh_path)\n",
    "yeo_rh_atlas = load_surf_data(yeo_rh_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot atlas\n",
    "\n",
    "fsaverage = datasets.load_fsaverage('fsaverage5')\n",
    "fsaverage_sulcal = datasets.load_fsaverage_data(data_type=\"sulcal\")\n",
    "\n",
    "ntp.plot(\n",
    "    {\n",
    "        'lh': yeo_lh_atlas.flatten(),\n",
    "        'rh': yeo_rh_atlas.flatten()\n",
    "    },\n",
    "    threshold=0,\n",
    "    cmap=\"Set2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset ventral attention (salience) network, binarize\n",
    "salience_idx = 4\n",
    "salience_lh = np.where(yeo_lh_atlas == salience_idx, 1, 0)\n",
    "salience_rh = np.where(yeo_rh_atlas == salience_idx, 1, 0)\n",
    "\n",
    "visual_idx = 1\n",
    "visual_lh = np.where(yeo_lh_atlas == visual_idx, 1, 0)\n",
    "visual_rh = np.where(yeo_rh_atlas == visual_idx, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntp.plot(\n",
    "    {\n",
    "        'lh': salience_lh,\n",
    "        'rh': salience_rh\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### Import feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fis_path = params['model_results_path'] + 'vertex_ridge_feature_importance.pkl'\n",
    "fis, best_fis, avg_fis, haufe_avg, haufe_fis = pd.read_pickle(fis_path)\n",
    "\n",
    "# peel off EEA and pTF\n",
    "EEA_hauf = haufe_avg['EEA']\n",
    "tf_hauf = haufe_avg['tf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def broadcast_to_fsaverage(fis_agg: pd.Series, n_vertices=10242) -> pd.DataFrame:\n",
    "    \"\"\"Broadcast feature importance to fsaverage5.\n",
    "\n",
    "    Args:\n",
    "        fis_agg (pd.Series): Feature importance.\n",
    "        n_vertices (int, optional): Number of vertices. Defaults to 10242+1.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Broadcasted feature importance.\n",
    "    \"\"\"\n",
    "\n",
    "    def _split_hemisphere(df):\n",
    "        df = df.reset_index(names=[\"correct\", \"condition\", \"hemisphere\"])\n",
    "        lh = df[df[\"hemisphere\"] == \"lh\"].drop(columns=\"hemisphere\")\n",
    "        rh = df[df[\"hemisphere\"] == \"rh\"].drop(columns=\"hemisphere\")\n",
    "\n",
    "        return lh, rh\n",
    "\n",
    "    fis = fis_agg.copy()\n",
    "\n",
    "    fis.index = fis.index.str.split(\"_\", expand=True)\n",
    "    fis = fis.unstack(level=2)\n",
    "    # fis = fis.unstack()\n",
    "\n",
    "    # convert columns to integers and sort\n",
    "    fis.columns = fis.columns.astype(int)\n",
    "    fis = fis.reindex(sorted(fis.columns), axis=1)\n",
    "\n",
    "    # need to insert blank columns for missing vertices\n",
    "    vertex_names = [*range(1, n_vertices + 1)]\n",
    "    # vertex_names = [*range(0, n_vertices)]\n",
    "    null_df = pd.DataFrame(np.nan, columns=vertex_names, index=fis.index)\n",
    "    null_df = null_df.drop(columns=fis.columns)\n",
    "\n",
    "    df = fis.join(null_df, how=\"outer\")\n",
    "    lh, rh = _split_hemisphere(df)\n",
    "\n",
    "    return lh, rh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_to_dict(df: pd.DataFrame, idx=['correct', 'condition']):\n",
    "    \"\"\"Take dataframe (hemi) where each row is a double-index condition\n",
    "    and return a dictionary of numpy arrays. \"\"\"\n",
    "\n",
    "    return (df\n",
    "        .assign(cond=lambda x: x[idx[0]] + '_' + x[idx[1]])\n",
    "        .drop(columns=idx)\n",
    "        .set_index('cond')\n",
    "        .groupby(level=0)\n",
    "        .apply(lambda x: x.values.flatten())\n",
    "        .to_dict()\n",
    "    )\n",
    "\n",
    "def apply_mask(hemi_dict, hemi_mask):\n",
    "\n",
    "    masked = {}\n",
    "    for condition, values in hemi_dict.items():\n",
    "        \n",
    "        masked[condition] = np.where(hemi_mask, values, 0)\n",
    "    \n",
    "    return masked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(lh, rh, ax):\n",
    "\n",
    "    def _flat_df(lh, rh):\n",
    "        array = np.concatenate([lh, rh])\n",
    "        array = array[array != 0]\n",
    "        posneg = array > 0\n",
    "\n",
    "        return pd.DataFrame({\n",
    "            'values': array,\n",
    "            'posneg': posneg\n",
    "        })\n",
    "\n",
    "    df = _flat_df(lh, rh)\n",
    "\n",
    "    n_pos = sum(df['posneg'])\n",
    "    prop = n_pos / len(df)\n",
    "\n",
    "    mean = df['values'].mean()\n",
    "    std = df['values'].std()\n",
    "\n",
    "    label_map = {True: 'Pos.', False: \"Neg.\"}\n",
    "    df = df.replace(label_map)\n",
    "\n",
    "    sns.histplot(\n",
    "        data=df,\n",
    "        x='values',\n",
    "        hue='posneg',\n",
    "        palette='seismic',\n",
    "        hue_order=['Neg.', 'Pos.'],\n",
    "        ax=ax\n",
    "    )\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_ylabel(\"Number of Features\")\n",
    "\n",
    "    ax.set_title(\n",
    "        # f'Pos. vertices: {n_pos}; neg. vertices: {n_neg}'\n",
    "        rf'N Pos. Features: {n_pos} ({prop:.2%}); Mean FIS = {mean:.2e} $\\pm$ {std:.2e}'\n",
    "    )\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# plot_hist(lh_salience['correct_stop'], rh_salience['correct_stop'], ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_masked_figure(lh, rh, conditions, target_map, title):\n",
    "\n",
    "    fig, axs = plt.subplots(ncols=len(conditions), nrows=2, \n",
    "                        figsize=(30, 8), sharey=True, \n",
    "                        height_ratios=[2.25, 1])\n",
    "\n",
    "    for i, condition in enumerate(conditions):\n",
    "\n",
    "        lh_plot = lh[condition]\n",
    "        rh_plot = rh[condition]\n",
    "\n",
    "        ax = axs[0, i]\n",
    "\n",
    "        ax.set_title(target_map[condition])\n",
    "\n",
    "        ntp.plot({'lh': lh_plot, 'rh': rh_plot},\n",
    "            threshold=0,\n",
    "            cmap='seismic',\n",
    "            colorbar=False,\n",
    "            ax=ax\n",
    "        )\n",
    "\n",
    "        ax = axs[1, i]\n",
    "\n",
    "\n",
    "        plot_hist(lh_plot, rh_plot, ax)\n",
    "    \n",
    "    plt.suptitle(title, size=20, x=0.15)\n",
    "\n",
    "def generate_plot(fis, mask_lh, mask_rh, target_map, title):\n",
    "\n",
    "    lh_tab, rh_tab = broadcast_to_fsaverage(fis)\n",
    "    lh_masked = apply_mask(table_to_dict(lh_tab), mask_lh)\n",
    "    rh_masked = apply_mask(table_to_dict(rh_tab), mask_rh)\n",
    "\n",
    "    conditions = lh_masked.keys()\n",
    "\n",
    "    make_masked_figure(lh_masked, rh_masked, conditions, target_map, title)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Ventral Attention (Salience) network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### EEA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_map = params['target_map']\n",
    "\n",
    "# generate_plot(EEA_hauf, salience_lh, salience_rh, target_map, \"EEA\")\n",
    "# plt.savefig(params['plot_output_path'] + 'EEA_salience_fis.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "### $pTF$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_plot(tf_hauf, salience_lh, salience_rh, target_map, r\"$p$TF\")\n",
    "\n",
    "# plt.savefig(params['plot_output_path'] + 'tf_salience_fis.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## Visual network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "### EEA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_plot(EEA_hauf, visual_lh, visual_rh, target_map, \"EEA\")\n",
    "# plt.savefig(params['plot_output_path'] + 'EEA_visual_fis.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "### $pTF$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_plot(tf_hauf, visual_lh, visual_rh, target_map, r\"$p$TF\")\n",
    "# plt.savefig(params['plot_output_path'] + 'tf_visual_fis.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "## Exmine ACC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from netneurotools import datasets as netds\n",
    "schaefer = netds.fetch_schaefer2018(data_dir=\"../../data/01_raw/nnt/\", version='fsaverage5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "schaefer['100Parcels7Networks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "schaefer_lh = schaefer['400Parcels7Networks'][0]\n",
    "schaefer_rh = schaefer['400Parcels7Networks'][1]\n",
    "\n",
    "schaefer_lh = load_surf_data(schaefer_lh)\n",
    "schaefer_rh = load_surf_data(schaefer_rh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "mni_schaefer = datasets.fetch_atlas_schaefer_2018()\n",
    "labs = [l.decode() for l in mni_schaefer.labels]\n",
    "\n",
    "rois = [\n",
    "    # 'Med_1',\n",
    "    'Med_2',\n",
    "    # 'Med_3',\n",
    "    # 'Med_4'\n",
    "    # 'Med_5'\n",
    "    # 'Med_6'\n",
    "    # 'Med_7'\n",
    "    # 'Med_8'\n",
    "]\n",
    "\n",
    "salience_rois = [(idx, label) for idx, label in enumerate(labs) for roi in rois if roi in label]\n",
    "salience_lh_idx = [item[0] for item in salience_rois if 'LH' in item[1]]\n",
    "salience_rh_idx = [item[0] for item in salience_rois if 'RH' in item[1]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ntp.plot(\n",
    "    {\n",
    "        'lh': np.where(np.isin(schaefer_lh, salience_lh_idx), 1, 0),\n",
    "        'rh': np.where(np.isin(schaefer_rh, salience_rh_idx), 1, 0)\n",
    "    },\n",
    "    threshold=0\n",
    ")\n",
    "\n",
    "salience_rois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_lh_mask = np.where(np.isin(schaefer_lh, salience_lh_idx), 1, 0)\n",
    "acc_rh_mask = np.where(np.isin(schaefer_rh, salience_rh_idx), 1, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_plot(haufe_avg['EEA'], acc_lh_mask, acc_lh_mask, target_map, 'EEA (ACC)')\n",
    "plt.savefig(params['plot_output_path'] + 'EEA_acc_mask.png', dpi=300, bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sst-rdex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
